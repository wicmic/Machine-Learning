{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross-Validation 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "       Gewinn  Preis in Mio  Quadratmeter    Stadt\n0    119000.0         21.88        3938.0   Berlin\n81    25000.0          9.07        1002.0   Berlin\n80   124000.0         26.31        5201.0   Berlin\n77    64000.0         14.90        2220.0   Berlin\n148   35000.0         15.80        2281.0   Berlin\n..        ...           ...           ...      ...\n115   76000.0         18.78        2186.0  München\n82    58000.0         19.93        3306.0  München\n117   33000.0         16.04        1505.0  München\n13    62000.0         17.08        1941.0  München\n93    62000.0         16.15        1799.0  München\n\n[150 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gewinn</th>\n      <th>Preis in Mio</th>\n      <th>Quadratmeter</th>\n      <th>Stadt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>119000.0</td>\n      <td>21.88</td>\n      <td>3938.0</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>81</th>\n      <td>25000.0</td>\n      <td>9.07</td>\n      <td>1002.0</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>124000.0</td>\n      <td>26.31</td>\n      <td>5201.0</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>64000.0</td>\n      <td>14.90</td>\n      <td>2220.0</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>35000.0</td>\n      <td>15.80</td>\n      <td>2281.0</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>115</th>\n      <td>76000.0</td>\n      <td>18.78</td>\n      <td>2186.0</td>\n      <td>München</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>58000.0</td>\n      <td>19.93</td>\n      <td>3306.0</td>\n      <td>München</td>\n    </tr>\n    <tr>\n      <th>117</th>\n      <td>33000.0</td>\n      <td>16.04</td>\n      <td>1505.0</td>\n      <td>München</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>62000.0</td>\n      <td>17.08</td>\n      <td>1941.0</td>\n      <td>München</td>\n    </tr>\n    <tr>\n      <th>93</th>\n      <td>62000.0</td>\n      <td>16.15</td>\n      <td>1799.0</td>\n      <td>München</td>\n    </tr>\n  </tbody>\n</table>\n<p>150 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data/hotels.csv\")    #nur 6 Exemplare ist nur um den Split zu sehen.\n",
    "#df = pd.read_csv(\"data/hotels.csv\")   [:20]    # so soll es eher sein....\n",
    "\n",
    "df.sort_values(\"Stadt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"Gewinn\", \"Quadratmeter\"]].values\n",
    "Y = df[[\"Preis in Mio\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.190e+05, 3.938e+03],\n       [2.500e+05, 3.986e+03],\n       [2.500e+05, 2.574e+03],\n       [1.450e+05, 4.155e+03],\n       [1.100e+05, 3.795e+03],\n       [2.460e+05, 2.773e+03],\n       [5.400e+04, 6.340e+02],\n       [2.000e+03, 8.200e+01],\n       [1.140e+05, 3.706e+03],\n       [4.700e+04, 1.692e+03],\n       [5.400e+04, 1.989e+03],\n       [1.240e+05, 2.616e+03],\n       [1.250e+05, 3.358e+03],\n       [6.200e+04, 1.941e+03],\n       [2.500e+05, 1.831e+03],\n       [2.400e+04, 8.000e+02],\n       [1.020e+05, 2.700e+03],\n       [2.600e+04, 1.257e+03],\n       [8.500e+04, 2.644e+03],\n       [1.820e+05, 2.001e+03],\n       [7.400e+04, 1.581e+03],\n       [5.000e+03, 8.200e+01],\n       [1.340e+05, 2.412e+03],\n       [1.400e+04, 7.690e+02],\n       [8.400e+04, 3.815e+03],\n       [1.240e+05, 3.122e+03],\n       [3.200e+04, 1.492e+03],\n       [2.500e+05, 5.250e+02],\n       [5.300e+04, 1.217e+03],\n       [3.200e+04, 1.497e+03],\n       [6.300e+04, 3.101e+03],\n       [8.800e+04, 2.644e+03],\n       [1.560e+05, 3.631e+03],\n       [1.380e+05, 1.461e+03],\n       [3.700e+04, 1.492e+03],\n       [8.600e+04, 2.408e+03],\n       [1.700e+04, 8.590e+02],\n       [2.300e+04, 7.030e+02],\n       [1.360e+05, 4.908e+03],\n       [1.290e+05, 2.545e+03],\n       [3.400e+04, 1.847e+03],\n       [1.800e+04, 5.020e+02],\n       [1.370e+05, 3.478e+03],\n       [7.300e+04, 7.560e+02],\n       [1.560e+05, 5.099e+03],\n       [2.100e+04, 1.215e+03],\n       [9.100e+04, 3.107e+03],\n       [7.200e+04, 2.375e+03],\n       [1.010e+05, 2.101e+03],\n       [2.500e+05, 4.832e+03],\n       [5.700e+04, 2.458e+03],\n       [8.300e+04, 4.561e+03],\n       [8.700e+04, 4.044e+03],\n       [1.410e+05, 3.896e+03],\n       [9.900e+04, 2.630e+03],\n       [2.500e+05, 3.249e+03],\n       [9.900e+04, 2.409e+03],\n       [1.130e+05, 2.618e+03],\n       [8.300e+04, 3.366e+03],\n       [2.900e+04, 1.625e+03],\n       [6.800e+04, 3.149e+03],\n       [1.210e+05, 3.944e+03],\n       [7.100e+04, 3.162e+03],\n       [6.400e+04, 1.993e+03],\n       [2.500e+05, 2.583e+03],\n       [9.700e+04, 2.301e+03],\n       [4.000e+03, 1.710e+02],\n       [2.500e+05, 3.876e+03],\n       [1.300e+04, 3.040e+02],\n       [2.500e+05, 3.849e+03],\n       [6.600e+04, 2.795e+03],\n       [2.500e+05, 5.702e+03],\n       [7.500e+04, 4.082e+03],\n       [1.250e+05, 3.910e+03],\n       [1.260e+05, 4.565e+03],\n       [2.500e+05, 4.436e+03],\n       [2.500e+05, 1.355e+03],\n       [6.400e+04, 2.220e+03],\n       [9.700e+04, 3.674e+03],\n       [9.100e+04, 2.847e+03],\n       [1.240e+05, 5.201e+03],\n       [2.500e+04, 1.002e+03],\n       [5.800e+04, 3.306e+03],\n       [5.700e+04, 2.952e+03],\n       [1.900e+04, 7.230e+02],\n       [2.300e+04, 7.600e+02],\n       [2.600e+04, 1.241e+03],\n       [9.600e+04, 3.168e+03],\n       [2.500e+05, 5.741e+03],\n       [4.500e+04, 1.873e+03],\n       [3.000e+03, 1.140e+02],\n       [1.160e+05, 3.707e+03],\n       [8.000e+04, 3.165e+03],\n       [6.200e+04, 1.799e+03],\n       [8.500e+04, 6.470e+02],\n       [2.000e+04, 3.960e+02],\n       [6.100e+04, 1.346e+03],\n       [1.420e+05, 5.427e+03],\n       [1.560e+05, 3.085e+03],\n       [3.900e+04, 1.594e+03],\n       [1.630e+05, 3.619e+03],\n       [1.280e+05, 1.127e+03],\n       [7.100e+04, 2.985e+03],\n       [6.700e+04, 2.770e+03],\n       [7.000e+03, 2.420e+02],\n       [2.500e+05, 5.519e+03],\n       [6.900e+04, 3.062e+03],\n       [1.200e+05, 4.681e+03],\n       [3.400e+04, 2.501e+03],\n       [2.500e+04, 1.690e+03],\n       [8.900e+04, 4.494e+03],\n       [1.760e+05, 2.671e+03],\n       [2.500e+05, 5.549e+03],\n       [1.030e+05, 1.275e+03],\n       [5.600e+04, 2.218e+03],\n       [7.600e+04, 2.186e+03],\n       [7.000e+03, 3.800e+02],\n       [3.300e+04, 1.505e+03],\n       [1.210e+05, 4.151e+03],\n       [4.400e+04, 1.781e+03],\n       [2.500e+05, 5.607e+03],\n       [1.250e+05, 5.643e+03],\n       [1.250e+05, 3.309e+03],\n       [4.800e+04, 3.302e+03],\n       [9.500e+04, 3.429e+03],\n       [2.500e+05, 2.584e+03],\n       [1.350e+05, 3.224e+03],\n       [4.400e+04, 7.880e+02],\n       [1.920e+05, 3.708e+03],\n       [6.300e+04, 1.489e+03],\n       [8.700e+04, 2.244e+03],\n       [1.100e+04, 1.790e+02],\n       [1.210e+05, 2.220e+03],\n       [1.040e+05, 3.374e+03],\n       [2.270e+05, 1.696e+03],\n       [2.500e+05, 2.115e+03],\n       [2.500e+05, 3.558e+03],\n       [3.500e+04, 1.021e+03],\n       [1.870e+05, 4.008e+03],\n       [8.000e+03, 2.670e+02],\n       [2.500e+05, 5.256e+03],\n       [2.320e+05, 2.337e+03],\n       [8.000e+03, 4.490e+02],\n       [2.130e+05, 4.763e+03],\n       [1.590e+05, 3.078e+03],\n       [4.500e+04, 1.775e+03],\n       [2.500e+05, 4.058e+03],\n       [3.200e+04, 1.668e+03],\n       [3.500e+04, 2.281e+03],\n       [9.000e+04, 2.297e+03]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[119000.,   3938.],\n       [110000.,   3795.]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[0, 4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [  0   1   2   4   5   6   7   8   9  10  11  12  13  14  15  18  19  20\n",
      "  21  24  25  26  27  28  29  30  31  32  33  34  35  36  38  39  40  41\n",
      "  42  43  44  45  46  47  49  50  51  52  53  54  55  56  57  58  59  60\n",
      "  61  62  64  65  66  67  68  69  70  71  72  75  76  77  78  79  80  81\n",
      "  82  83  84  85  86  87  88  89  90  91  93  94  95  97  98  99 100 101\n",
      " 102 103 105 106 107 109 110 111 112 113 114 115 116 117 118 119 120 121\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "test: [  3  16  17  22  23  37  48  63  73  74  92  96 104 108 122]\n",
      "-----------\n",
      "0.824279306523935\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  19  20  21  22  23  24  25  26  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  57\n",
      "  59  60  61  62  63  64  65  66  68  69  70  71  72  73  74  75  76  77\n",
      "  78  79  80  81  82  83  84  85  86  87  88  89  90  91  92  94  95  96\n",
      "  97  98  99 100 101 102 103 104 105 106 108 109 112 113 115 116 117 119\n",
      " 120 121 122 123 124 125 126 128 129 130 131 132 133 134 136 137 138 139\n",
      " 140 142 143 144 145 146 147 148 149]\n",
      "test: [ 18  27  55  56  58  67  93 107 110 111 114 118 127 135 141]\n",
      "-----------\n",
      "0.8075241006923057\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  14  15  16  17  18\n",
      "  19  21  22  23  24  25  27  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  46  48  49  52  53  54  55  56  57  58  59  60\n",
      "  61  62  63  65  66  67  68  69  71  72  73  74  75  76  77  78  79  80\n",
      "  81  82  84  85  86  87  88  90  91  92  93  94  95  96  97  98  99 100\n",
      " 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118\n",
      " 119 120 121 122 123 124 125 126 127 128 129 130 131 134 135 136 137 138\n",
      " 139 141 142 143 144 145 146 147 148]\n",
      "test: [ 13  20  26  45  47  50  51  64  70  83  89 132 133 140 149]\n",
      "-----------\n",
      "0.6706057799095448\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  53  54  55  56\n",
      "  57  58  59  60  63  64  65  66  67  68  69  70  71  73  74  76  77  78\n",
      "  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 116 117\n",
      " 118 119 120 122 123 124 125 126 127 128 129 130 131 132 133 134 135 137\n",
      " 138 139 140 141 142 143 146 147 149]\n",
      "test: [ 15  28  52  61  62  72  75  79  80 115 121 136 144 145 148]\n",
      "-----------\n",
      "0.8539109187176092\n",
      "train: [  0   2   3   5   6   7   8   9  10  12  13  14  15  16  17  18  19  20\n",
      "  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38\n",
      "  39  40  42  43  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  61  62  63  64  65  66  67  68  70  71  72  73  74  75  77  78  79\n",
      "  80  81  82  83  84  86  87  88  89  90  92  93  94  95  96  97  98  99\n",
      " 100 101 102 104 105 106 107 108 109 110 111 113 114 115 116 117 118 119\n",
      " 120 121 122 123 124 126 127 129 130 131 132 133 134 135 136 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "test: [  1   4  11  41  44  60  69  76  85  91 103 112 125 128 137]\n",
      "-----------\n",
      "0.8503413247999319\n",
      "train: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  44  45  47  48  49  50  51  52  53  54  55  56  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  72  73  74  75  76  77\n",
      "  78  79  80  83  84  85  86  87  88  89  90  91  92  93  94  95  96  98\n",
      "  99 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117\n",
      " 118 120 121 122 123 125 126 127 128 129 130 132 133 134 135 136 137 139\n",
      " 140 141 142 143 144 145 147 148 149]\n",
      "test: [ 24  25  43  46  57  71  81  82  97 100 119 124 131 138 146]\n",
      "-----------\n",
      "0.8978528839482811\n",
      "train: [  1   2   3   4   5   6   7   8   9  11  13  14  15  16  17  18  19  20\n",
      "  22  23  24  25  26  27  28  29  30  31  32  36  37  40  41  42  43  44\n",
      "  45  46  47  48  49  50  51  52  53  55  56  57  58  60  61  62  63  64\n",
      "  65  66  67  68  69  70  71  72  73  74  75  76  78  79  80  81  82  83\n",
      "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n",
      " 103 104 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121\n",
      " 122 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "test: [  0  10  12  21  33  34  35  38  39  54  59  77  84 105 123]\n",
      "-----------\n",
      "0.7823284481208619\n",
      "train: [  0   1   3   4   5   6   9  10  11  12  13  15  16  17  18  19  20  21\n",
      "  22  23  24  25  26  27  28  29  30  31  33  34  35  36  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  62  63  64  65  67  69  70  71  72  73  74  75  76  77  79  80\n",
      "  81  82  83  84  85  86  88  89  90  91  92  93  94  96  97  98  99 100\n",
      " 101 103 104 105 106 107 108 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 127 128 129 130 131 132 133 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "test: [  2   7   8  14  32  49  66  68  78  87  95 102 109 126 134]\n",
      "-----------\n",
      "0.774155516835802\n",
      "train: [  0   1   2   3   4   6   7   8  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  31  32  33  34  35  36  37  38\n",
      "  39  41  43  44  45  46  47  48  49  50  51  52  54  55  56  57  58  59\n",
      "  60  61  62  63  64  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  91  92  93  94  95  96  97\n",
      "  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 114 115 116\n",
      " 118 119 120 121 122 123 124 125 126 127 128 129 131 132 133 134 135 136\n",
      " 137 138 140 141 144 145 146 148 149]\n",
      "test: [  5   9  30  40  42  53  65  90 113 117 130 139 142 143 147]\n",
      "-----------\n",
      "0.8537579863877598\n",
      "train: [  0   1   2   3   4   5   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  20  21  22  23  24  25  26  27  28  30  32  33  34  35  37  38  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76\n",
      "  77  78  79  80  81  82  83  84  85  87  89  90  91  92  93  95  96  97\n",
      " 100 102 103 104 105 107 108 109 110 111 112 113 114 115 117 118 119 121\n",
      " 122 123 124 125 126 127 128 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "test: [  6  19  29  31  36  86  88  94  98  99 101 106 116 120 129]\n",
      "-----------\n",
      "0.7584570458533348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle= True)    #Anzahl der Splits\n",
    "score = 0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"train: \" + str(train_index))\n",
    "    print(\"test: \" + str(test_index))\n",
    "    print(\"-----------\")\n",
    "    X_test = X[test_index]\n",
    "    X_train = X[train_index]\n",
    "    \n",
    "    y_test = Y[test_index]\n",
    "    y_train = Y[train_index]\n",
    "    \n",
    "    # Lineare Regression trainieren\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    score += model.score(X_test, y_test)\n",
    "    print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8073213311789367\n"
     ]
    }
   ],
   "source": [
    "#Durchschnitt aller Scores gibt ein relistisches Bild. \n",
    "#Man setzt die Anzahl der Spilts üblicherweise zwischen 4 und 10.\n",
    "print(score / kf.get_n_splits(X))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
