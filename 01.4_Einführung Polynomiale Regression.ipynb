{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung in die Polynomiale Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/fields.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    length     profit   width\n0    807.0   634630.0  1032.0\n1    299.0   124074.0   337.0\n2    431.0  1338300.0  1631.0\n3    744.0   327720.0   553.0\n4    364.0   500244.0   827.0\n5    977.0  1284950.0  1608.0\n6    969.0    96045.0   207.0\n7    339.0   868313.0  1208.0\n8    443.0  1471693.0  1723.0\n9    488.0   156123.0   392.0\n10   506.0   860984.0  1253.0\n11   310.0   474912.0   863.0\n12   791.0   359585.0   774.0\n13   551.0  1134907.0  1424.0\n14   562.0    53871.0    32.0\n15   156.0   717514.0  1116.0\n16   694.0  1085443.0  1386.0\n17   290.0   422056.0   869.0\n18   820.0   654704.0  1044.0\n19   506.0   398611.0   724.0\n20   614.0   681866.0   982.0\n21   633.0  1556410.0  1724.0\n22   640.0   182040.0   360.0\n23   563.0   601289.0   995.0\n24   328.0  1261952.0  1489.0\n25   462.0   643479.0  1117.0\n26   151.0   143325.0   239.0\n27   566.0  1189117.0  1469.0\n28   675.0   578658.0  1066.0\n29   774.0   308172.0   637.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>length</th>\n      <th>profit</th>\n      <th>width</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>807.0</td>\n      <td>634630.0</td>\n      <td>1032.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>299.0</td>\n      <td>124074.0</td>\n      <td>337.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>431.0</td>\n      <td>1338300.0</td>\n      <td>1631.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>744.0</td>\n      <td>327720.0</td>\n      <td>553.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>364.0</td>\n      <td>500244.0</td>\n      <td>827.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>977.0</td>\n      <td>1284950.0</td>\n      <td>1608.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>969.0</td>\n      <td>96045.0</td>\n      <td>207.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>339.0</td>\n      <td>868313.0</td>\n      <td>1208.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>443.0</td>\n      <td>1471693.0</td>\n      <td>1723.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>488.0</td>\n      <td>156123.0</td>\n      <td>392.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>506.0</td>\n      <td>860984.0</td>\n      <td>1253.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>310.0</td>\n      <td>474912.0</td>\n      <td>863.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>791.0</td>\n      <td>359585.0</td>\n      <td>774.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>551.0</td>\n      <td>1134907.0</td>\n      <td>1424.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>562.0</td>\n      <td>53871.0</td>\n      <td>32.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>156.0</td>\n      <td>717514.0</td>\n      <td>1116.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>694.0</td>\n      <td>1085443.0</td>\n      <td>1386.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>290.0</td>\n      <td>422056.0</td>\n      <td>869.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>820.0</td>\n      <td>654704.0</td>\n      <td>1044.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>506.0</td>\n      <td>398611.0</td>\n      <td>724.0</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>614.0</td>\n      <td>681866.0</td>\n      <td>982.0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>633.0</td>\n      <td>1556410.0</td>\n      <td>1724.0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>640.0</td>\n      <td>182040.0</td>\n      <td>360.0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>563.0</td>\n      <td>601289.0</td>\n      <td>995.0</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>328.0</td>\n      <td>1261952.0</td>\n      <td>1489.0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>462.0</td>\n      <td>643479.0</td>\n      <td>1117.0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>151.0</td>\n      <td>143325.0</td>\n      <td>239.0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>566.0</td>\n      <td>1189117.0</td>\n      <td>1469.0</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>675.0</td>\n      <td>578658.0</td>\n      <td>1066.0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>774.0</td>\n      <td>308172.0</td>\n      <td>637.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9151374097035715\n"
     ]
    }
   ],
   "source": [
    "# Beispiel: Normale, lineare Regression\n",
    "\n",
    "X = df[[\"width\", \"length\"]].values\n",
    "Y = df[[\"profit\"]].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state = 42, test_size = 0.25)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "PolynomialFeatures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "PolynomialFeatures(include_bias=False)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PolynomialFeatures(include_bias=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PolynomialFeatures</label><div class=\"sk-toggleable__content\"><pre>PolynomialFeatures(include_bias=False)</pre></div></div></div></div></div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "#include_bias = False  - Wenn das auf True ist, dann gibt es eine zusätzliche Spalte mit einer 1, um den Intercept zu trainieren, falls diser nicht vorhanden wäre.\n",
    "\n",
    "pf.fit(X_train) #wäre hier strenggenommen nicht nötig, aber andere Prozesse verlangen das später"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1093.,  486.],\n       [ 626.,  324.],\n       [1608.,  977.],\n       [1243.,  674.],\n       [  58.,  821.],\n       [ 777.,  561.],\n       [1501.,   18.],\n       [1348.,  258.],\n       [1092.,  263.],\n       [  61.,  606.],\n       [ 783.,   55.],\n       [ 873.,  109.],\n       [   4.,  550.],\n       [ 774.,  791.],\n       [ 920.,  650.],\n       [1053.,  494.],\n       [1074.,  788.],\n       [1093.,  473.],\n       [ 915.,  536.],\n       [1052.,  526.],\n       [1821.,  483.],\n       [1023.,  818.],\n       [1708.,  475.],\n       [ 550.,  124.],\n       [1265., 1059.],\n       [1635.,  382.],\n       [ 239.,  151.],\n       [ 629.,  603.],\n       [ 864.,  394.],\n       [ 767.,  726.],\n       [1631.,  431.],\n       [ 363.,  926.],\n       [1009., 1074.],\n       [1795.,  385.],\n       [1706.,  811.],\n       [1456.,  397.],\n       [1123.,  199.],\n       [ 507.,  698.],\n       [ 862.,  869.],\n       [1167.,  771.],\n       [ 360.,  640.],\n       [ 906.,  606.],\n       [ 709.,  356.],\n       [1151.,  556.],\n       [ 863.,  310.],\n       [1310., 1036.],\n       [1193.,  715.],\n       [ 207.,  969.],\n       [1469.,  566.],\n       [1736.,  451.],\n       [ 827.,  364.],\n       [ 561.,  688.],\n       [1444.,   84.],\n       [1578.,  385.],\n       [1412.,  687.],\n       [ 850.,  628.],\n       [1253.,  506.],\n       [ 738.,  429.],\n       [1734.,  745.],\n       [1401.,  378.],\n       [1930.,  621.],\n       [1032.,  807.],\n       [ 418.,  319.],\n       [ 926.,  656.],\n       [1421.,  473.],\n       [ 681.,  564.],\n       [1354.,  733.],\n       [ 937.,  438.],\n       [ 999.,  546.],\n       [1066.,  675.],\n       [1265.,  231.],\n       [ 610.,  520.],\n       [1727.,  298.],\n       [1044.,  580.],\n       [1117.,  462.],\n       [ 995.,  563.],\n       [1014.,  407.],\n       [ 576.,   41.],\n       [1400.,  106.],\n       [1759.,  764.],\n       [1549.,  111.],\n       [ 644.,  524.],\n       [  36.,  198.],\n       [1211.,  713.],\n       [1380.,  262.],\n       [ 471.,  517.],\n       [ 553.,  744.],\n       [2018.,  525.],\n       [1021.,  668.],\n       [ 367.,  187.],\n       [1142.,  641.],\n       [1171.,  281.],\n       [ 929.,  672.],\n       [1210.,  591.],\n       [1710.,  330.],\n       [1896.,  139.],\n       [1208.,  339.],\n       [ 112.,  621.],\n       [ 617.,  181.],\n       [ 760.,  381.],\n       [ 825.,  355.],\n       [ 483.,   13.],\n       [ 860.,  437.],\n       [1723.,  443.],\n       [1424.,  551.],\n       [ 836.,  120.],\n       [ 830.,  701.],\n       [1497.,  560.],\n       [ 869.,  290.],\n       [ 653.,  785.],\n       [ 523.,  243.],\n       [1399.,   64.],\n       [ 461.,  222.],\n       [ 622.,  574.],\n       [1018.,  450.],\n       [1617.,  791.],\n       [ 866.,   45.],\n       [ 311.,  371.],\n       [ 941.,  498.],\n       [1071.,  690.],\n       [ 218.,  999.],\n       [  37.,  951.],\n       [1724.,  633.],\n       [1598.,   52.],\n       [ 345., 1061.],\n       [1365.,  869.],\n       [ 954.,  838.],\n       [ 935.,   47.],\n       [   6.,  774.],\n       [ 780.,  687.],\n       [ 337.,  299.],\n       [ 929.,  768.],\n       [ 762.,  322.],\n       [1906.,  533.],\n       [ 822., 1214.],\n       [ 660.,  831.],\n       [1202.,  364.],\n       [ 802.,  280.],\n       [2325.,  199.],\n       [ 490.,  818.],\n       [1344.,  421.],\n       [ 187.,  188.],\n       [ 982.,  614.],\n       [ 679.,  314.],\n       [ 682.,  407.],\n       [ 601.,  791.],\n       [  32.,  562.],\n       [1747.,  425.],\n       [1110.,  907.],\n       [ 903.,  276.]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n",
    "#Ein Array aus Paaren \"length\" und \"width\" bzw. wir sagen x1 und x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.093000e+03, 4.860000e+02, 1.194649e+06, 5.311980e+05,\n        2.361960e+05],\n       [6.260000e+02, 3.240000e+02, 3.918760e+05, 2.028240e+05,\n        1.049760e+05],\n       [1.608000e+03, 9.770000e+02, 2.585664e+06, 1.571016e+06,\n        9.545290e+05],\n       [1.243000e+03, 6.740000e+02, 1.545049e+06, 8.377820e+05,\n        4.542760e+05],\n       [5.800000e+01, 8.210000e+02, 3.364000e+03, 4.761800e+04,\n        6.740410e+05],\n       [7.770000e+02, 5.610000e+02, 6.037290e+05, 4.358970e+05,\n        3.147210e+05],\n       [1.501000e+03, 1.800000e+01, 2.253001e+06, 2.701800e+04,\n        3.240000e+02],\n       [1.348000e+03, 2.580000e+02, 1.817104e+06, 3.477840e+05,\n        6.656400e+04],\n       [1.092000e+03, 2.630000e+02, 1.192464e+06, 2.871960e+05,\n        6.916900e+04],\n       [6.100000e+01, 6.060000e+02, 3.721000e+03, 3.696600e+04,\n        3.672360e+05],\n       [7.830000e+02, 5.500000e+01, 6.130890e+05, 4.306500e+04,\n        3.025000e+03],\n       [8.730000e+02, 1.090000e+02, 7.621290e+05, 9.515700e+04,\n        1.188100e+04],\n       [4.000000e+00, 5.500000e+02, 1.600000e+01, 2.200000e+03,\n        3.025000e+05],\n       [7.740000e+02, 7.910000e+02, 5.990760e+05, 6.122340e+05,\n        6.256810e+05],\n       [9.200000e+02, 6.500000e+02, 8.464000e+05, 5.980000e+05,\n        4.225000e+05],\n       [1.053000e+03, 4.940000e+02, 1.108809e+06, 5.201820e+05,\n        2.440360e+05],\n       [1.074000e+03, 7.880000e+02, 1.153476e+06, 8.463120e+05,\n        6.209440e+05],\n       [1.093000e+03, 4.730000e+02, 1.194649e+06, 5.169890e+05,\n        2.237290e+05],\n       [9.150000e+02, 5.360000e+02, 8.372250e+05, 4.904400e+05,\n        2.872960e+05],\n       [1.052000e+03, 5.260000e+02, 1.106704e+06, 5.533520e+05,\n        2.766760e+05],\n       [1.821000e+03, 4.830000e+02, 3.316041e+06, 8.795430e+05,\n        2.332890e+05],\n       [1.023000e+03, 8.180000e+02, 1.046529e+06, 8.368140e+05,\n        6.691240e+05],\n       [1.708000e+03, 4.750000e+02, 2.917264e+06, 8.113000e+05,\n        2.256250e+05],\n       [5.500000e+02, 1.240000e+02, 3.025000e+05, 6.820000e+04,\n        1.537600e+04],\n       [1.265000e+03, 1.059000e+03, 1.600225e+06, 1.339635e+06,\n        1.121481e+06],\n       [1.635000e+03, 3.820000e+02, 2.673225e+06, 6.245700e+05,\n        1.459240e+05],\n       [2.390000e+02, 1.510000e+02, 5.712100e+04, 3.608900e+04,\n        2.280100e+04],\n       [6.290000e+02, 6.030000e+02, 3.956410e+05, 3.792870e+05,\n        3.636090e+05],\n       [8.640000e+02, 3.940000e+02, 7.464960e+05, 3.404160e+05,\n        1.552360e+05],\n       [7.670000e+02, 7.260000e+02, 5.882890e+05, 5.568420e+05,\n        5.270760e+05],\n       [1.631000e+03, 4.310000e+02, 2.660161e+06, 7.029610e+05,\n        1.857610e+05],\n       [3.630000e+02, 9.260000e+02, 1.317690e+05, 3.361380e+05,\n        8.574760e+05],\n       [1.009000e+03, 1.074000e+03, 1.018081e+06, 1.083666e+06,\n        1.153476e+06],\n       [1.795000e+03, 3.850000e+02, 3.222025e+06, 6.910750e+05,\n        1.482250e+05],\n       [1.706000e+03, 8.110000e+02, 2.910436e+06, 1.383566e+06,\n        6.577210e+05],\n       [1.456000e+03, 3.970000e+02, 2.119936e+06, 5.780320e+05,\n        1.576090e+05],\n       [1.123000e+03, 1.990000e+02, 1.261129e+06, 2.234770e+05,\n        3.960100e+04],\n       [5.070000e+02, 6.980000e+02, 2.570490e+05, 3.538860e+05,\n        4.872040e+05],\n       [8.620000e+02, 8.690000e+02, 7.430440e+05, 7.490780e+05,\n        7.551610e+05],\n       [1.167000e+03, 7.710000e+02, 1.361889e+06, 8.997570e+05,\n        5.944410e+05],\n       [3.600000e+02, 6.400000e+02, 1.296000e+05, 2.304000e+05,\n        4.096000e+05],\n       [9.060000e+02, 6.060000e+02, 8.208360e+05, 5.490360e+05,\n        3.672360e+05],\n       [7.090000e+02, 3.560000e+02, 5.026810e+05, 2.524040e+05,\n        1.267360e+05],\n       [1.151000e+03, 5.560000e+02, 1.324801e+06, 6.399560e+05,\n        3.091360e+05],\n       [8.630000e+02, 3.100000e+02, 7.447690e+05, 2.675300e+05,\n        9.610000e+04],\n       [1.310000e+03, 1.036000e+03, 1.716100e+06, 1.357160e+06,\n        1.073296e+06],\n       [1.193000e+03, 7.150000e+02, 1.423249e+06, 8.529950e+05,\n        5.112250e+05],\n       [2.070000e+02, 9.690000e+02, 4.284900e+04, 2.005830e+05,\n        9.389610e+05],\n       [1.469000e+03, 5.660000e+02, 2.157961e+06, 8.314540e+05,\n        3.203560e+05],\n       [1.736000e+03, 4.510000e+02, 3.013696e+06, 7.829360e+05,\n        2.034010e+05],\n       [8.270000e+02, 3.640000e+02, 6.839290e+05, 3.010280e+05,\n        1.324960e+05],\n       [5.610000e+02, 6.880000e+02, 3.147210e+05, 3.859680e+05,\n        4.733440e+05],\n       [1.444000e+03, 8.400000e+01, 2.085136e+06, 1.212960e+05,\n        7.056000e+03],\n       [1.578000e+03, 3.850000e+02, 2.490084e+06, 6.075300e+05,\n        1.482250e+05],\n       [1.412000e+03, 6.870000e+02, 1.993744e+06, 9.700440e+05,\n        4.719690e+05],\n       [8.500000e+02, 6.280000e+02, 7.225000e+05, 5.338000e+05,\n        3.943840e+05],\n       [1.253000e+03, 5.060000e+02, 1.570009e+06, 6.340180e+05,\n        2.560360e+05],\n       [7.380000e+02, 4.290000e+02, 5.446440e+05, 3.166020e+05,\n        1.840410e+05],\n       [1.734000e+03, 7.450000e+02, 3.006756e+06, 1.291830e+06,\n        5.550250e+05],\n       [1.401000e+03, 3.780000e+02, 1.962801e+06, 5.295780e+05,\n        1.428840e+05],\n       [1.930000e+03, 6.210000e+02, 3.724900e+06, 1.198530e+06,\n        3.856410e+05],\n       [1.032000e+03, 8.070000e+02, 1.065024e+06, 8.328240e+05,\n        6.512490e+05],\n       [4.180000e+02, 3.190000e+02, 1.747240e+05, 1.333420e+05,\n        1.017610e+05],\n       [9.260000e+02, 6.560000e+02, 8.574760e+05, 6.074560e+05,\n        4.303360e+05],\n       [1.421000e+03, 4.730000e+02, 2.019241e+06, 6.721330e+05,\n        2.237290e+05],\n       [6.810000e+02, 5.640000e+02, 4.637610e+05, 3.840840e+05,\n        3.180960e+05],\n       [1.354000e+03, 7.330000e+02, 1.833316e+06, 9.924820e+05,\n        5.372890e+05],\n       [9.370000e+02, 4.380000e+02, 8.779690e+05, 4.104060e+05,\n        1.918440e+05],\n       [9.990000e+02, 5.460000e+02, 9.980010e+05, 5.454540e+05,\n        2.981160e+05],\n       [1.066000e+03, 6.750000e+02, 1.136356e+06, 7.195500e+05,\n        4.556250e+05],\n       [1.265000e+03, 2.310000e+02, 1.600225e+06, 2.922150e+05,\n        5.336100e+04],\n       [6.100000e+02, 5.200000e+02, 3.721000e+05, 3.172000e+05,\n        2.704000e+05],\n       [1.727000e+03, 2.980000e+02, 2.982529e+06, 5.146460e+05,\n        8.880400e+04],\n       [1.044000e+03, 5.800000e+02, 1.089936e+06, 6.055200e+05,\n        3.364000e+05],\n       [1.117000e+03, 4.620000e+02, 1.247689e+06, 5.160540e+05,\n        2.134440e+05],\n       [9.950000e+02, 5.630000e+02, 9.900250e+05, 5.601850e+05,\n        3.169690e+05],\n       [1.014000e+03, 4.070000e+02, 1.028196e+06, 4.126980e+05,\n        1.656490e+05],\n       [5.760000e+02, 4.100000e+01, 3.317760e+05, 2.361600e+04,\n        1.681000e+03],\n       [1.400000e+03, 1.060000e+02, 1.960000e+06, 1.484000e+05,\n        1.123600e+04],\n       [1.759000e+03, 7.640000e+02, 3.094081e+06, 1.343876e+06,\n        5.836960e+05],\n       [1.549000e+03, 1.110000e+02, 2.399401e+06, 1.719390e+05,\n        1.232100e+04],\n       [6.440000e+02, 5.240000e+02, 4.147360e+05, 3.374560e+05,\n        2.745760e+05],\n       [3.600000e+01, 1.980000e+02, 1.296000e+03, 7.128000e+03,\n        3.920400e+04],\n       [1.211000e+03, 7.130000e+02, 1.466521e+06, 8.634430e+05,\n        5.083690e+05],\n       [1.380000e+03, 2.620000e+02, 1.904400e+06, 3.615600e+05,\n        6.864400e+04],\n       [4.710000e+02, 5.170000e+02, 2.218410e+05, 2.435070e+05,\n        2.672890e+05],\n       [5.530000e+02, 7.440000e+02, 3.058090e+05, 4.114320e+05,\n        5.535360e+05],\n       [2.018000e+03, 5.250000e+02, 4.072324e+06, 1.059450e+06,\n        2.756250e+05],\n       [1.021000e+03, 6.680000e+02, 1.042441e+06, 6.820280e+05,\n        4.462240e+05],\n       [3.670000e+02, 1.870000e+02, 1.346890e+05, 6.862900e+04,\n        3.496900e+04],\n       [1.142000e+03, 6.410000e+02, 1.304164e+06, 7.320220e+05,\n        4.108810e+05],\n       [1.171000e+03, 2.810000e+02, 1.371241e+06, 3.290510e+05,\n        7.896100e+04],\n       [9.290000e+02, 6.720000e+02, 8.630410e+05, 6.242880e+05,\n        4.515840e+05],\n       [1.210000e+03, 5.910000e+02, 1.464100e+06, 7.151100e+05,\n        3.492810e+05],\n       [1.710000e+03, 3.300000e+02, 2.924100e+06, 5.643000e+05,\n        1.089000e+05],\n       [1.896000e+03, 1.390000e+02, 3.594816e+06, 2.635440e+05,\n        1.932100e+04],\n       [1.208000e+03, 3.390000e+02, 1.459264e+06, 4.095120e+05,\n        1.149210e+05],\n       [1.120000e+02, 6.210000e+02, 1.254400e+04, 6.955200e+04,\n        3.856410e+05],\n       [6.170000e+02, 1.810000e+02, 3.806890e+05, 1.116770e+05,\n        3.276100e+04],\n       [7.600000e+02, 3.810000e+02, 5.776000e+05, 2.895600e+05,\n        1.451610e+05],\n       [8.250000e+02, 3.550000e+02, 6.806250e+05, 2.928750e+05,\n        1.260250e+05],\n       [4.830000e+02, 1.300000e+01, 2.332890e+05, 6.279000e+03,\n        1.690000e+02],\n       [8.600000e+02, 4.370000e+02, 7.396000e+05, 3.758200e+05,\n        1.909690e+05],\n       [1.723000e+03, 4.430000e+02, 2.968729e+06, 7.632890e+05,\n        1.962490e+05],\n       [1.424000e+03, 5.510000e+02, 2.027776e+06, 7.846240e+05,\n        3.036010e+05],\n       [8.360000e+02, 1.200000e+02, 6.988960e+05, 1.003200e+05,\n        1.440000e+04],\n       [8.300000e+02, 7.010000e+02, 6.889000e+05, 5.818300e+05,\n        4.914010e+05],\n       [1.497000e+03, 5.600000e+02, 2.241009e+06, 8.383200e+05,\n        3.136000e+05],\n       [8.690000e+02, 2.900000e+02, 7.551610e+05, 2.520100e+05,\n        8.410000e+04],\n       [6.530000e+02, 7.850000e+02, 4.264090e+05, 5.126050e+05,\n        6.162250e+05],\n       [5.230000e+02, 2.430000e+02, 2.735290e+05, 1.270890e+05,\n        5.904900e+04],\n       [1.399000e+03, 6.400000e+01, 1.957201e+06, 8.953600e+04,\n        4.096000e+03],\n       [4.610000e+02, 2.220000e+02, 2.125210e+05, 1.023420e+05,\n        4.928400e+04],\n       [6.220000e+02, 5.740000e+02, 3.868840e+05, 3.570280e+05,\n        3.294760e+05],\n       [1.018000e+03, 4.500000e+02, 1.036324e+06, 4.581000e+05,\n        2.025000e+05],\n       [1.617000e+03, 7.910000e+02, 2.614689e+06, 1.279047e+06,\n        6.256810e+05],\n       [8.660000e+02, 4.500000e+01, 7.499560e+05, 3.897000e+04,\n        2.025000e+03],\n       [3.110000e+02, 3.710000e+02, 9.672100e+04, 1.153810e+05,\n        1.376410e+05],\n       [9.410000e+02, 4.980000e+02, 8.854810e+05, 4.686180e+05,\n        2.480040e+05],\n       [1.071000e+03, 6.900000e+02, 1.147041e+06, 7.389900e+05,\n        4.761000e+05],\n       [2.180000e+02, 9.990000e+02, 4.752400e+04, 2.177820e+05,\n        9.980010e+05],\n       [3.700000e+01, 9.510000e+02, 1.369000e+03, 3.518700e+04,\n        9.044010e+05],\n       [1.724000e+03, 6.330000e+02, 2.972176e+06, 1.091292e+06,\n        4.006890e+05],\n       [1.598000e+03, 5.200000e+01, 2.553604e+06, 8.309600e+04,\n        2.704000e+03],\n       [3.450000e+02, 1.061000e+03, 1.190250e+05, 3.660450e+05,\n        1.125721e+06],\n       [1.365000e+03, 8.690000e+02, 1.863225e+06, 1.186185e+06,\n        7.551610e+05],\n       [9.540000e+02, 8.380000e+02, 9.101160e+05, 7.994520e+05,\n        7.022440e+05],\n       [9.350000e+02, 4.700000e+01, 8.742250e+05, 4.394500e+04,\n        2.209000e+03],\n       [6.000000e+00, 7.740000e+02, 3.600000e+01, 4.644000e+03,\n        5.990760e+05],\n       [7.800000e+02, 6.870000e+02, 6.084000e+05, 5.358600e+05,\n        4.719690e+05],\n       [3.370000e+02, 2.990000e+02, 1.135690e+05, 1.007630e+05,\n        8.940100e+04],\n       [9.290000e+02, 7.680000e+02, 8.630410e+05, 7.134720e+05,\n        5.898240e+05],\n       [7.620000e+02, 3.220000e+02, 5.806440e+05, 2.453640e+05,\n        1.036840e+05],\n       [1.906000e+03, 5.330000e+02, 3.632836e+06, 1.015898e+06,\n        2.840890e+05],\n       [8.220000e+02, 1.214000e+03, 6.756840e+05, 9.979080e+05,\n        1.473796e+06],\n       [6.600000e+02, 8.310000e+02, 4.356000e+05, 5.484600e+05,\n        6.905610e+05],\n       [1.202000e+03, 3.640000e+02, 1.444804e+06, 4.375280e+05,\n        1.324960e+05],\n       [8.020000e+02, 2.800000e+02, 6.432040e+05, 2.245600e+05,\n        7.840000e+04],\n       [2.325000e+03, 1.990000e+02, 5.405625e+06, 4.626750e+05,\n        3.960100e+04],\n       [4.900000e+02, 8.180000e+02, 2.401000e+05, 4.008200e+05,\n        6.691240e+05],\n       [1.344000e+03, 4.210000e+02, 1.806336e+06, 5.658240e+05,\n        1.772410e+05],\n       [1.870000e+02, 1.880000e+02, 3.496900e+04, 3.515600e+04,\n        3.534400e+04],\n       [9.820000e+02, 6.140000e+02, 9.643240e+05, 6.029480e+05,\n        3.769960e+05],\n       [6.790000e+02, 3.140000e+02, 4.610410e+05, 2.132060e+05,\n        9.859600e+04],\n       [6.820000e+02, 4.070000e+02, 4.651240e+05, 2.775740e+05,\n        1.656490e+05],\n       [6.010000e+02, 7.910000e+02, 3.612010e+05, 4.753910e+05,\n        6.256810e+05],\n       [3.200000e+01, 5.620000e+02, 1.024000e+03, 1.798400e+04,\n        3.158440e+05],\n       [1.747000e+03, 4.250000e+02, 3.052009e+06, 7.424750e+05,\n        1.806250e+05],\n       [1.110000e+03, 9.070000e+02, 1.232100e+06, 1.006770e+06,\n        8.226490e+05],\n       [9.030000e+02, 2.760000e+02, 8.154090e+05, 2.492280e+05,\n        7.617600e+04]])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.transform(X_train)\n",
    "#erzeugt  jetzt 5 Zahlen pro Example und zwar: x1, x2, x1*x1, X1*x2,  x2*x2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 0],\n       [0, 1],\n       [2, 0],\n       [1, 1],\n       [0, 2]], dtype=int64)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#der Bauplan hierfür ist mit\n",
    "pf.powers_\n",
    "#abrufbar. Dort sind die Potenzen der 5 Spalten sichtbar. \n",
    "# width ^ 1 * length ^ 0\n",
    "# width ^ 2 * length ^ 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.093000e+03, 1.194649e+06],\n       [6.260000e+02, 3.918760e+05],\n       [1.608000e+03, 2.585664e+06],\n       [1.243000e+03, 1.545049e+06],\n       [5.800000e+01, 3.364000e+03],\n       [7.770000e+02, 6.037290e+05],\n       [1.501000e+03, 2.253001e+06],\n       [1.348000e+03, 1.817104e+06],\n       [1.092000e+03, 1.192464e+06],\n       [6.100000e+01, 3.721000e+03],\n       [7.830000e+02, 6.130890e+05],\n       [8.730000e+02, 7.621290e+05],\n       [4.000000e+00, 1.600000e+01],\n       [7.740000e+02, 5.990760e+05],\n       [9.200000e+02, 8.464000e+05],\n       [1.053000e+03, 1.108809e+06],\n       [1.074000e+03, 1.153476e+06],\n       [1.093000e+03, 1.194649e+06],\n       [9.150000e+02, 8.372250e+05],\n       [1.052000e+03, 1.106704e+06],\n       [1.821000e+03, 3.316041e+06],\n       [1.023000e+03, 1.046529e+06],\n       [1.708000e+03, 2.917264e+06],\n       [5.500000e+02, 3.025000e+05],\n       [1.265000e+03, 1.600225e+06],\n       [1.635000e+03, 2.673225e+06],\n       [2.390000e+02, 5.712100e+04],\n       [6.290000e+02, 3.956410e+05],\n       [8.640000e+02, 7.464960e+05],\n       [7.670000e+02, 5.882890e+05],\n       [1.631000e+03, 2.660161e+06],\n       [3.630000e+02, 1.317690e+05],\n       [1.009000e+03, 1.018081e+06],\n       [1.795000e+03, 3.222025e+06],\n       [1.706000e+03, 2.910436e+06],\n       [1.456000e+03, 2.119936e+06],\n       [1.123000e+03, 1.261129e+06],\n       [5.070000e+02, 2.570490e+05],\n       [8.620000e+02, 7.430440e+05],\n       [1.167000e+03, 1.361889e+06],\n       [3.600000e+02, 1.296000e+05],\n       [9.060000e+02, 8.208360e+05],\n       [7.090000e+02, 5.026810e+05],\n       [1.151000e+03, 1.324801e+06],\n       [8.630000e+02, 7.447690e+05],\n       [1.310000e+03, 1.716100e+06],\n       [1.193000e+03, 1.423249e+06],\n       [2.070000e+02, 4.284900e+04],\n       [1.469000e+03, 2.157961e+06],\n       [1.736000e+03, 3.013696e+06],\n       [8.270000e+02, 6.839290e+05],\n       [5.610000e+02, 3.147210e+05],\n       [1.444000e+03, 2.085136e+06],\n       [1.578000e+03, 2.490084e+06],\n       [1.412000e+03, 1.993744e+06],\n       [8.500000e+02, 7.225000e+05],\n       [1.253000e+03, 1.570009e+06],\n       [7.380000e+02, 5.446440e+05],\n       [1.734000e+03, 3.006756e+06],\n       [1.401000e+03, 1.962801e+06],\n       [1.930000e+03, 3.724900e+06],\n       [1.032000e+03, 1.065024e+06],\n       [4.180000e+02, 1.747240e+05],\n       [9.260000e+02, 8.574760e+05],\n       [1.421000e+03, 2.019241e+06],\n       [6.810000e+02, 4.637610e+05],\n       [1.354000e+03, 1.833316e+06],\n       [9.370000e+02, 8.779690e+05],\n       [9.990000e+02, 9.980010e+05],\n       [1.066000e+03, 1.136356e+06],\n       [1.265000e+03, 1.600225e+06],\n       [6.100000e+02, 3.721000e+05],\n       [1.727000e+03, 2.982529e+06],\n       [1.044000e+03, 1.089936e+06],\n       [1.117000e+03, 1.247689e+06],\n       [9.950000e+02, 9.900250e+05],\n       [1.014000e+03, 1.028196e+06],\n       [5.760000e+02, 3.317760e+05],\n       [1.400000e+03, 1.960000e+06],\n       [1.759000e+03, 3.094081e+06],\n       [1.549000e+03, 2.399401e+06],\n       [6.440000e+02, 4.147360e+05],\n       [3.600000e+01, 1.296000e+03],\n       [1.211000e+03, 1.466521e+06],\n       [1.380000e+03, 1.904400e+06],\n       [4.710000e+02, 2.218410e+05],\n       [5.530000e+02, 3.058090e+05],\n       [2.018000e+03, 4.072324e+06],\n       [1.021000e+03, 1.042441e+06],\n       [3.670000e+02, 1.346890e+05],\n       [1.142000e+03, 1.304164e+06],\n       [1.171000e+03, 1.371241e+06],\n       [9.290000e+02, 8.630410e+05],\n       [1.210000e+03, 1.464100e+06],\n       [1.710000e+03, 2.924100e+06],\n       [1.896000e+03, 3.594816e+06],\n       [1.208000e+03, 1.459264e+06],\n       [1.120000e+02, 1.254400e+04],\n       [6.170000e+02, 3.806890e+05],\n       [7.600000e+02, 5.776000e+05],\n       [8.250000e+02, 6.806250e+05],\n       [4.830000e+02, 2.332890e+05],\n       [8.600000e+02, 7.396000e+05],\n       [1.723000e+03, 2.968729e+06],\n       [1.424000e+03, 2.027776e+06],\n       [8.360000e+02, 6.988960e+05],\n       [8.300000e+02, 6.889000e+05],\n       [1.497000e+03, 2.241009e+06],\n       [8.690000e+02, 7.551610e+05],\n       [6.530000e+02, 4.264090e+05],\n       [5.230000e+02, 2.735290e+05],\n       [1.399000e+03, 1.957201e+06],\n       [4.610000e+02, 2.125210e+05],\n       [6.220000e+02, 3.868840e+05],\n       [1.018000e+03, 1.036324e+06],\n       [1.617000e+03, 2.614689e+06],\n       [8.660000e+02, 7.499560e+05],\n       [3.110000e+02, 9.672100e+04],\n       [9.410000e+02, 8.854810e+05],\n       [1.071000e+03, 1.147041e+06],\n       [2.180000e+02, 4.752400e+04],\n       [3.700000e+01, 1.369000e+03],\n       [1.724000e+03, 2.972176e+06],\n       [1.598000e+03, 2.553604e+06],\n       [3.450000e+02, 1.190250e+05],\n       [1.365000e+03, 1.863225e+06],\n       [9.540000e+02, 9.101160e+05],\n       [9.350000e+02, 8.742250e+05],\n       [6.000000e+00, 3.600000e+01],\n       [7.800000e+02, 6.084000e+05],\n       [3.370000e+02, 1.135690e+05],\n       [9.290000e+02, 8.630410e+05],\n       [7.620000e+02, 5.806440e+05],\n       [1.906000e+03, 3.632836e+06],\n       [8.220000e+02, 6.756840e+05],\n       [6.600000e+02, 4.356000e+05],\n       [1.202000e+03, 1.444804e+06],\n       [8.020000e+02, 6.432040e+05],\n       [2.325000e+03, 5.405625e+06],\n       [4.900000e+02, 2.401000e+05],\n       [1.344000e+03, 1.806336e+06],\n       [1.870000e+02, 3.496900e+04],\n       [9.820000e+02, 9.643240e+05],\n       [6.790000e+02, 4.610410e+05],\n       [6.820000e+02, 4.651240e+05],\n       [6.010000e+02, 3.612010e+05],\n       [3.200000e+01, 1.024000e+03],\n       [1.747000e+03, 3.052009e+06],\n       [1.110000e+03, 1.232100e+06],\n       [9.030000e+02, 8.154090e+05]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.transform(X_train)[:, [0, 2]]\n",
    "# schneidet z.B. X1, X1*X1 heraus... (nur Beispiel, das zeigen soll, wie man Spalten herausschneidet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = pf.transform(X_train)\n",
    "X_test_transformed = pf.transform(X_test)\n",
    "\n",
    "#X_train_transformed = pf.transform(X_train)[:, [0, 1, 2, 3, 4]]\n",
    "#X_test_transformed = pf.transform(X_test)[:, [0, 1, 2, 3, 4]]\n",
    "# Durch manuelles trial-and-error (Herumprobieren), kann man herausfinden, was hier wirklich\n",
    "# ausschlaggebend ist, um auf R2 = 0,988 zu kommen.\n",
    "#X_train_transformed = pf.transform(X_train)[:, [0, 2]]\n",
    "#X_test_transformed = pf.transform(X_test)[:, [0, 2]]\n",
    "\n",
    "\n",
    "X_train_transformed = pf.transform(X_train)[:, [0,2]]\n",
    "X_test_transformed = pf.transform(X_test)[:, [0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9881840549313348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(model.score(X_test_transformed, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[98.55966017,  0.42889992]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([74023.35586782])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[  1.,   2.,   3.,   4.,   1.,   2.,   3.,   4.,   4.,   6.,   8.,\n          9.,  12.,  16.],\n       [  2.,  10.,   3.,   4.,   4.,  20.,   6.,   8., 100.,  30.,  40.,\n          9.,  12.,  16.],\n       [  2.,  11.,   3.,   4.,   4.,  22.,   6.,   8., 121.,  33.,  44.,\n          9.,  12.,  16.],\n       [  2.,  12.,   3.,   4.,   4.,  24.,   6.,   8., 144.,  36.,  48.,\n          9.,  12.,  16.]])"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Was passiert eigentlich bei pf.transform genau\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "a = [[1,2,3,4],\n",
    " [2,10,3,4],\n",
    " [2,11,3,4],\n",
    " [2,12,3,4]]\n",
    "pf.fit(a)\n",
    "pf.transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1, 0, 0, 0],\n       [0, 1, 0, 0],\n       [0, 0, 1, 0],\n       [0, 0, 0, 1],\n       [2, 0, 0, 0],\n       [1, 1, 0, 0],\n       [1, 0, 1, 0],\n       [1, 0, 0, 1],\n       [0, 2, 0, 0],\n       [0, 1, 1, 0],\n       [0, 1, 0, 1],\n       [0, 0, 2, 0],\n       [0, 0, 1, 1],\n       [0, 0, 0, 2]], dtype=int64)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.powers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Zeile - gegeben: 1 2 3 4 \n",
    "# 1 2 3 4\n",
    "# 1*1  1*2 1*3 1*4\n",
    "# 2*2  2*3  2*4\n",
    "# 3*3 3*4\n",
    "# 4*4\n",
    "\n",
    "# 2. Zeile - gegeben: 2 10 3 4\n",
    "# 2 10 3 4\n",
    "# 2*2 2*10 2*3 2*4\n",
    "# 10*10 10*30 10*4\n",
    "# 3*3 3*4\n",
    "# 4*4\n",
    "\n",
    "# usw. usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 1.,  2.],\n       [ 2., 20.],\n       [ 2., 22.],\n       [ 2., 24.]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf.transform(a)[:, [0, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
